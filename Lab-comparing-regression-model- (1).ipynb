{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this final lab, we will model our data. Import sklearn `train_test_split` and separate the data.\n",
    "\n",
    "2. Separate X_train and X_test into numerical and categorical (X_train_cat , X_train_num , X_test_cat , X_test_num)\n",
    "\n",
    "3. Use X_train_num to fit scalers.  Transform BOTH X_train_num and X_test_num.\n",
    "\n",
    "4. Encode the categorical variables X_train_cat and X_test_cat (See the hint below for encoding categorical data!!!)\n",
    "\n",
    "5. Since the model will only accept numerical data, check and make sure that every column is numerical, if some are not, change it using encoding.\n",
    "\n",
    "6. Try a simple linear regression with all the data to see whether we are getting good results.\n",
    "\n",
    "7. Great! Now define a function that takes a list of models and train (and tests) them so we can try a lot of them without repeating code.\n",
    "\n",
    "8. Use the function to check `LinearRegressor` and `KNeighborsRegressor`.\n",
    "\n",
    "9. You can check also the `MLPRegressor` for this task!\n",
    "\n",
    "10. Check and discuss the results.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should deal with the categorical variables as shown below (for ordinal encoding, dummy code has been provided as well):\n",
    "Encoder Type | Column \n",
    "-----------------|-----------------\n",
    "One hot | state\n",
    "Ordinal | coverage\n",
    "Ordinal | employmentstatus\n",
    "Ordinal | location code\n",
    "One hot | marital status\n",
    "One hot | policy type\n",
    "One hot | policy\n",
    "One hot | renew offercustomer_df\n",
    "One hot | sales channel\n",
    "One hot | vehicle class\n",
    "Ordinal | vehicle size\n",
    "Ordinal | education\n",
    "One hot | response\n",
    "One hot | gender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy code\n",
    "\n",
    "data[\"coverage\"] = data[\"coverage\"].map({\"Basic\" : 0, \"Extended\" : 1, \"Premium\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_decision_regions\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import pandas as pd #tablas https://pandas.pydata.org/docs/user_guide/pyarrow.html\n",
    "import numpy as np #estadistica https://numpy.org/doc/1.25/user/index.html#user\n",
    "import matplotlib.pyplot as plt #gráficos https://matplotlib.org/stable/plot_types/index.html\n",
    "import seaborn as sns #gráficos https://seaborn.pydata.org/tutorial/regression.html\n",
    "from sklearn import linear_model #modelo de regresion https://scikit-learn.org/stable/\n",
    "from sklearn.preprocessing import MinMaxScaler # do not use the function Normalise() - it does something entirely different\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime #https://docs.python.org/3/library/datetime.html\n",
    "from datetime import timedelta #this is a good time to learn about dates and timestamps. You can find some info here:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import ttest_1samp\n",
    "import scipy.stats as st\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this final lab, we will model our data. Import sklearn `train_test_split` and separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cat = pd.read_csv('categorical22_08.csv')\n",
    "df_num = pd.read_csv('numerical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cat = df_cat.astype(str)\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df= pd.concat([df_num, df_cat], axis=1)\n",
    "df = df.drop(columns=[\"effective_to_date\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"23_08_df.csv\", index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Separate X_train and X_test into numerical and categorical (X_train_cat , X_train_num , X_test_cat , X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(['total_claim_amount'],axis=1)\n",
    "y = df['total_claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use X_train_num to fit scalers.  Transform BOTH X_train_num and X_test_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(include = np.number)\n",
    "X_test_num  = X_test.select_dtypes(include = np.number)\n",
    "X_train_cat = X_train.select_dtypes(include = object)\n",
    "X_test_cat  = X_test.select_dtypes(include = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MinMaxtransformer = MinMaxScaler().fit(X_train_num) #IMPORTANTE ESTO ES EL NOMBRE DEL TRANSFORMADOR\n",
    "transformer = MinMaxScaler().fit(X_train_num) #Aplicar el min y el max, pero recuerda que X  tiene que ser valores numericos\n",
    "x_train_norm= transformer.transform(X_train_num) #Convertirlo entre 0 y 1 \n",
    "print(x_train_norm.shape)\n",
    "x_train_norm\n",
    "x_train_normalized= pd.DataFrame(x_train_norm, columns=X_train_num.columns) #df.normalizado para asi poder tener un data set normalizado al que llamar\n",
    "x_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test_norm= transformer.transform(X_test_num) #Convertirlo entre 0 y 1 \n",
    "print(x_test_norm.shape)\n",
    "x_test_norm\n",
    "x_test_normalized= pd.DataFrame(x_test_norm, columns=X_test_num.columns) #df.normalizado para asi poder tener un data set normalizado al que llamar\n",
    "x_test_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Encode the categorical variables X_train_cat and X_test_cat (See the hint below for encoding categorical data!!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One encoding everything :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_cat = X_train.select_dtypes(include = object)\n",
    "X_test_cat  = X_test.select_dtypes(include = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "encoder = OneHotEncoder(handle_unknown='error', drop='first').fit(X_train_cat )\n",
    "categoricals_train_encoded = encoder.transform(X_train_cat).toarray()\n",
    "categoricals_test_encoded = encoder.transform(X_test_cat ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_train_encoded_df = pd.DataFrame(categoricals_train_encoded)\n",
    "categorical_train_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_test_encoded_df = pd.DataFrame(categoricals_test_encoded)\n",
    "categorical_test_encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Since the model will only accept numerical data, check and make sure that every column is numerical, if some are not, change it using encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_norm_enc = pd.concat([x_train_normalized, categorical_train_encoded_df], axis=1)\n",
    "X_train_norm_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_norm_enc.columns = X_train_norm_enc.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_norm_enc = pd.concat([x_test_normalized, categorical_test_encoded_df], axis=1)\n",
    "X_test_norm_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_norm_enc.columns = X_test_norm_enc.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_norm_enc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_norm_enc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Try a simple linear regression with all the data to see whether we are getting good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train_norm_enc,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test_norm_enc)\n",
    "r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Great! Now define a function that takes a list of models and train (and tests) them so we can try a lot of them without repeating code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_test_regression_models(models, X_train, X_test, y_train, y_test, test_size=0.2, random_state=100):\n",
    "    results = {}\n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        results[model_name] = r2\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Use the function to check `LinearRegressor` and `KNeighborsRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train_norm_enc\n",
    "X_test= X_test_norm_enc\n",
    "\n",
    "models_to_try = [LinearRegression(), KNeighborsRegressor()]\n",
    "\n",
    "results = train_and_test_regression_models(models_to_try, X_train, X_test, y_train, y_test)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " 9. You can check also the `MLPRegressor` for this task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_and_test_regression_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLPRegressor\n\u001b[0;32m      2\u001b[0m models_to_try \u001b[38;5;241m=\u001b[39m [MLPRegressor()]\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m train_and_test_regression_models(models_to_try, X_train, X_test, y_train, y_test)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_and_test_regression_models' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "models_to_try = [MLPRegressor()]\n",
    "\n",
    "results = train_and_test_regression_models(models_to_try, X_train, X_test, y_train, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. All of them have a similar explanatory power, besides the KNN (not K defined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
